# -*- coding: utf-8 -*-
"""smyandarr_Lab2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AqGNYRzrlLwDXig26ErlbG4l6ZIpSwJA
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install fortran-magic
# %matplotlib inline
# %load_ext fortranmagic

import sys; sys.path.append('..')

import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns

mpl.rc('figure', figsize=(12, 7))

ran_the_first_cell = True

jan2017 = pd.to_datetime(['2017-01-03 00:00:00+00:00',
 '2017-01-04 00:00:00+00:00',
 '2017-01-05 00:00:00+00:00',
 '2017-01-06 00:00:00+00:00',
 '2017-01-09 00:00:00+00:00',
 '2017-01-10 00:00:00+00:00',
 '2017-01-11 00:00:00+00:00',
 '2017-01-12 00:00:00+00:00',
 '2017-01-13 00:00:00+00:00',
 '2017-01-17 00:00:00+00:00',
 '2017-01-18 00:00:00+00:00',
 '2017-01-19 00:00:00+00:00',
 '2017-01-20 00:00:00+00:00',
 '2017-01-23 00:00:00+00:00',
 '2017-01-24 00:00:00+00:00',
 '2017-01-25 00:00:00+00:00',
 '2017-01-26 00:00:00+00:00',
 '2017-01-27 00:00:00+00:00',
 '2017-01-30 00:00:00+00:00',
 '2017-01-31 00:00:00+00:00',
 '2017-02-01 00:00:00+00:00'])
calendar = jan2017.values.astype('datetime64[D]')

event_dates = pd.to_datetime(['2017-01-06 00:00:00+00:00', 
                             '2017-01-07 00:00:00+00:00', 
                             '2017-01-08 00:00:00+00:00']).values.astype('datetime64[D]')
event_values = np.array([10, 15, 20])

"""<center>
  <h1>The PyData Toolbox</h1>
  <h3>Scott Sanderson (Twitter: @scottbsanderson, GitHub: ssanderson)</h3>
  <h3><a href="https://github.com/ssanderson/pydata-toolbox">https://github.com/ssanderson/pydata-toolbox</a></h3>
</center>

# About Me:

<img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/me.jpg" alt="Drawing" style="width: 300px;"/>

- Senior Engineer at [Quantopian](www.quantopian.com)
- Background in Mathematics and Philosophy
- **Twitter:** [@scottbsanderson](https://twitter.com/scottbsanderson)
- **GitHub:** [ssanderson](github.com/ssanderson)

## Outline

- Built-in Data Structures
- Numpy `array`
- Pandas `Series`/`DataFrame`
- Plotting and "Real-World" Analyses

# Data Structures

> Rule 5. Data dominates. If you've chosen the right data structures and organized things well, the algorithms
will almost always be self-evident. Data structures, not algorithms, are central to programming.

- *Notes on Programming in C*, by Rob Pike.

# Lists
"""

assert ran_the_first_cell, "Oh noes!"

l = [1, 'two', 3.0, 4, 5.0, "six"]
l

# Lists can be indexed like C-style arrays.
first = l[0]
second = l[1]
print("first:", first)
print("second:", second)

# Negative indexing gives elements relative to the end of the list.
last = l[-1]
penultimate = l[-2]
print("last:", last)
print("second to last:", penultimate)

# Lists can also be sliced, which makes a copy of elements between 
# start (inclusive) and stop (exclusive)
sublist = l[1:3]
sublist

# l[:N] is equivalent to l[0:N].
first_three = l[:3]
first_three

# l[3:] is equivalent to l[3:len(l)].
after_three = l[3:]
after_three

# There's also a third parameter, "step", which gets every Nth element.
l = ['a', 'b', 'c', 'd', 'e', 'f', 'g','h']
l[1:7:2]

# This is a cute way to reverse a list.
l[::-1]

# Lists can be grown efficiently (in O(1) amortized time).
l = [1, 2, 3, 4, 5]
print("Before:", l)
l.append('six')
print("After:", l)

# Comprehensions let us perform elementwise computations.
l = [1, 2, 3, 4, 5]
[x * 2 for x in l]

"""## Review: Python Lists

- Zero-indexed sequence of arbitrary Python values.
- Slicing syntax: `l[start:stop:step]` copies elements at regular intervals from `start` to `stop`.
- Efficient (`O(1)`) appends and removes from end.
- Comprehension syntax: `[f(x) for x in l if cond(x)]`.

# Dictionaries
"""

# Dictionaries are key-value mappings.
philosophers = {'David': 'Hume', 'Immanuel': 'Kant', 'Bertrand': 'Russell'}
philosophers

# Like lists, dictionaries are size-mutable.
philosophers['Ludwig'] = 'Wittgenstein'
philosophers

del philosophers['David']
philosophers

# No slicing.
philosophers['Bertrand':'Immanuel']

"""## Review: Python Dictionaries

- Unordered key-value mapping from (almost) arbitrary keys to arbitrary values.
- Efficient (`O(1)`) lookup, insertion, and deletion.
- No slicing (would require a notion of order).

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/pacino.gif" alt="Drawing" style="width: 100%;"/></center>
"""

# Suppose we have some matrices...
a = [[1, 2, 3],
     [2, 3, 4],
     [5, 6, 7],
     [1, 1, 1]]

b = [[1, 2, 3, 4],
     [2, 3, 4, 5]]

def matmul(A, B):
    """Multiply matrix A by matrix B."""
    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for col in range(cols_out)] for row in range(rows_out)]
    
    for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(B)):
                out[i][j] += A[i][k] * B[k][j]
    return out

"""<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/gross.gif" alt="Drawing" style="width: 50%;"/></center>

"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# matmul(a, b)

"""**My own example 0 - cpu info**"""

!cat /proc/cpuinfo

"""**My own example 1 - Changing in matmul(A, B) Python len(B) (# of rows of B) for len(A[0]) (# of columns of A)**"""

A = np.array([[1, 2, 3], [4, 5, 6]])  
B = np.array([[7, 8], [9, 10], [11, 12]])  

C = np.matmul(A, B)
print("Producto de matrices con las dimensiones originales", C)

A = np.array([[1, 2, 3], [4, 5, 6]])
B = np.array([[7, 8, 13], [9, 10, 14], [11, 12, 15]])
C = np.matmul(A, B.T)

print("Producto de matrices con B transpuesta", C)

"""**My own example 2 - Verifiying error with in matmul(A, B) Python with the original matrices when changing len(B) (# of rows of B) for len(A[0]) (# of colums of A)**"""

#El error ocurrira por que las matrices tienen las dimensiones incorrectas para ser operadas.
A = np.array([[1, 2, 3], [4, 5, 6]])
B = np.array([[7, 8, 13], [9, 10, 14]])
C = np.matmul(A, B)

"""**My own example 3 - Chekcing the mtarix multiplication compatibility condition  len(A[0]) == len(B)**"""

A = np.array([[1, 2, 3], [4, 5, 6]])
B = np.array([[7, 8, 13], [9, 10, 14]])

if A.shape[1] == B.shape[0]:
  print("la multiplicacion entre A y B es posible, victoria.")
else:
  print("no se puede realizar la multiplicacion")

"""**My own example 4 -  Verifiying error with in matmul(A, B) Python when checking the mtarix multiplication compatibility condition  len(A[0]) == len(B)**"""

A = np.array([[1, 2, 3], [4, 5, 6]])
B = np.array([[7, 8], [9, 10], [11, 12]])

if A.shape[1] != B.shape[0]:
    print("Las matrices no tienen una forma compatible que permita la multiplicacion.")
else:
 C = np.matmul(A, B)
print(C)

"""**My own example 5 - Deifining A and B that are compatiible for multiplcation**"""

A = np.array([[1, 2], [3, 4], [5, 6]])  
B = np.array([[7, 8, 9], [10, 11, 12]])  

C = np.matmul(A, B)
print("El resultado de la multiplicacion entre estas matrices sera una matris de 3x3", C)

"""**My own example 6 - Runinng the correct Python matrix multiplication code with the matrices with dimensions compatible for multiplication.**"""

import random

random.normalvariate(0,1)

a1 = [[11, 12, 13],
     [16, 15, 14],
     [17, 18, 19]]

b1 = [[11, 21, 31],
     [24, 36, 45],
      [23, 24, 12]]

def matmul(A, B):
    rows_out = len(A)
    cols_out = len(B[0])
    q = len(A[0])
    t = len(B)
    if(q!=t):
      print("Los tamaños de las matrices no son compatibles.")


    out = [[0 for col in range(cols_out)] for row in range(rows_out)]
    for x in range(rows_out):
        for z in range(cols_out):
            for k in range(len(B)):
                out[x][z] += A[x][k] * B[k][z]
    return out


matmul(a1,b1)

"""**My own example 7 - Running 10 times matmul(randa, randb) with randa and randb a randon matrices of 600 x 100 and 100 x 600 and calulating the average execution time**"""

import time
m = 600
n = 100
randa = np.random.rand(m, n)
randb = np.random.rand(n, m)
num_runs = 10
total_time = 0
for i in range(num_runs):
    start_time = time.time()
    np.matmul(randa, randb)
    end_time = time.time()
    total_time += end_time - start_time
    avg_time = total_time / num_runs

print(f"Tiempo promedio de operacion {num_runs} son: {avg_time:.6f} seconds")

"""**My own example 8 - Creating the average execution time data frame and adding Python's average execution time**"""

randa = np.random.rand(600, 100)
randb = np.random.rand(100, 600)
times = []
for i in range(100):
    start_time = time.time()
    result = np.matmul(randa, randb)
    end_time = time.time()
    times.append(end_time - start_time)
custom_avg_time = sum(times) / len(times)
df = pd.DataFrame({'Metodo': ['Custom', 'Python'],
                   'Tiempo de ejecucion': [custom_avg_time, np.nan]})
print(df)

"""**My own example 9 - Running 10 times randa and randb mutiplicaction as NumPy arrays  adding NumPy's average execution time**"""

randa = np.random.rand(600, 100)
randb = np.random.rand(100, 600)
np_times = []
for i in range(10):
    start_time = time.time()
    result = np.matmul(randa, randb)
    np_times.append(time.time() - start_time)

np_avg_time = np.mean(np_times)

print("Tiempo promedio de ejecucion en NumPy", np_avg_time)

import random

# Commented out IPython magic to ensure Python compatibility.
# %%time
# def random_matrix(m, n):
#     out = []
#     for row in range(m):
#         out.append([random.random() for _ in range(n)])
#     return out
# randa = random_matrix(600, 100)
# randb = random_matrix(100, 600)
# x = matmul(randa, randb)

# Maybe that's not that bad?  Let's try a simpler case.
def python_dot_product(xs, ys):
    return sum(x * y for x, y in zip(xs, ys))

# Commented out IPython magic to ensure Python compatibility.
# %%fortran
# subroutine fortran_dot_product(xs, ys, result)
#     double precision, intent(in) :: xs(:)
#     double precision, intent(in) :: ys(:)
#     double precision, intent(out) :: result
#     
#     result = sum(xs * ys)
# end

list_data = [float(i) for i in range(100000)]
array_data = np.array(list_data)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# python_dot_product(list_data, list_data)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# fortran_dot_product(array_data, array_data)

"""<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/sloth.gif" alt="Drawing" style="width: 1080px;"/></center>

**My own example 10 - Deifining A (2x2)  and B (2x2)**
"""

A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

"""**My own example 11 - Defining Fortran subroutine matmul(A,B) for 2x2 matrices**"""

fortran_dot_product(A, B)

"""**My own example 12 -Run Fortran subroutine matmul(A,B) with a and b 2x2 matrices**"""

fortran_dot_product(A,B)

"""**My own example 13 - Defining Fortran subroutine matmul(A,B) for 600x100 and 100x600 matrices**"""

fortran_dot_product(A,B)

"""**My own example 14 -Run Fortran subroutine matmul(A,B) with 600x100 and 100x600 matrices**"""

a = random_matrix(600, 100)
b = random_matrix(100, 600)
fortran_dot_product(a, b)

"""**My own example 15 - Running 10 times the  Fortran subroutine matmul(A,B) with 600x100 and 100x600 matrices and adding Fortran magic average execution time to the data frame**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# for i in range(10):
#   A = random_matrix(600, 100)
#   B = random_matrix(100, 600)
#   total = fortran_dot_product(A,B)
#   print(total)

"""**My own example 16 - Creating a  Fortran program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

def diez(A,B):
  for i in range(10):
    print(fortran_dot_product(A,B))

A = random_matrix(600, 100)
B = random_matrix(100, 600)
diez(A,B)

"""**My own example 17 - Running the Fortran program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

def diez(A,B):
  for i in range(10):
    print(fortran_dot_product(A,B))

A = random_matrix(600, 100)
B = random_matrix(100, 600)
diez(A,B)

"""**My own example 18 - Adding Fortran average execution time to the data frame**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# def diez(A,B):
#   for i in range(10):
#     print(fortran_dot_product(A,B))
# 
# A = random_matrix(600, 100)
# B = random_matrix(100, 600)
# diez(A,B)

"""**My own example 19 - Creating a c program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# 
# %%writefile multma.c
# #include <stdio.h>
# #include <stdlib.h>
# #include <time.h>       // for clock_t, clock(), CLOCKS_PER_SEC
# #include <unistd.h>     // for sleep()
# int main() {
#     int i, j, k;
#     int n = 600, m = 100, p = 600;
#     double *A = (double *) malloc(n * m * sizeof(double));
#     double *B = (double *) malloc(m * p * sizeof(double));
#     double *C = (double *) malloc(n * p * sizeof(double));
#     clock_t start, end;
#     double cpu_time_used;
# 
#     // Initialize matrices A and B with random values
#     srand(time(NULL));
#     for (i = 0; i < n * m; i++) {
#         A[i] = (double) rand() / RAND_MAX;
#     }
#     for (i = 0; i < m * p; i++) {
#         B[i] = (double) rand() / RAND_MAX;
#     }
# 
#     // Multiply matrices A and B
#     start = clock();
#     for (i = 0; i < n; i++) {
#         for (j = 0; j < p; j++) {
#             C[i * p + j] = 0.0;
#             for (k = 0; k < m; k++) {
#                 C[i * p + j] += A[i * m + k] * B[k * p + j];
#             }
#         }
#     }
#     end = clock();
# 
#     // Print the resulting matrix C and the execution time
#     printf("Matrix C:\n");
#     for (i = 0; i < n; i++) {
#         for (j = 0; j < p; j++) {
#             printf("%.2f ", C[i * p + j]);
#         }
#         printf("\n");
#     }
#     cpu_time_used = ((double) (end - start)) / CLOCKS_PER_SEC;
#     printf("Execution time: %.4f seconds\n", cpu_time_used);
# 
#     // Free memory
#     free(A);
#     free(B);
#     free(C);
# 
#     return 0;
# }

"""**My own example 20 - Running the c program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# !g++ multma.c -o matrix_mul
# !./matrix_mul

"""**My own example 21 - Adding c average execution time to the data frame**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# !g++ multma.c -o matrix_mul
# !./matrix_mul

"""**My own example 22 - Creating a C++ program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile multma.c
# #include <stdio.h>
# #include <stdlib.h>
# #include <time.h>       // for clock_t, clock(), CLOCKS_PER_SEC
# #include <unistd.h>     // for sleep()
# 
# using namespace std;
# 
# int main() {
#     int N = 10;
#     int m1 = 600, n1 = 100, m2 = 100, n2 = 600;
#     double* A = (double*) malloc(m1 * n1 * sizeof(double));
#     double* B = (double*) malloc(m2 * n2 * sizeof(double));
#     double* C = (double*) malloc(m1 * n2 * sizeof(double));
# 
#     
#     for (int i = 0; i < m1 * n1; i++) {
#         A[i] = (double) rand() / RAND_MAX;
#     }
#     for (int i = 0; i < m2 * n2; i++) {
#         B[i] = (double) rand() / RAND_MAX;
#     }
# 
#     
#     double total_time = 0.0;
#     for (int k = 0; k < N; k++) {
#         auto start_time = chrono::high_resolution_clock::now();
#         for (int i = 0; i < m1; i++) {
#             for (int j = 0; j < n2; j++) {
#                 double sum = 0.0;
#                 for (int h = 0; h < n1; h++) {
#                     sum += A[i*n1+h] * B[h*n2+j];
#                 }
#                 C[i*n2+j] = sum;
#             }
#         }
#         auto end_time = chrono::high_resolution_clock::now();
#         double time = chrono::duration_cast<chrono::microseconds>(end_time - start_time).count() / 1000000.0;
#         total_time += time;

"""**My own example 23 - Running the C++ program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile multma.c
# #include <stdio.h>
# #include <stdlib.h>
# #include <time.h>       // for clock_t, clock(), CLOCKS_PER_SEC
# #include <unistd.h>     // for sleep()
# 
# using namespace std;
# 
# int main() {
#     int N = 10;
#     int m1 = 600, n1 = 100, m2 = 100, n2 = 600;
#     double* A = (double*) malloc(m1 * n1 * sizeof(double));
#     double* B = (double*) malloc(m2 * n2 * sizeof(double));
#     double* C = (double*) malloc(m1 * n2 * sizeof(double));
# 
#     
#     for (int i = 0; i < m1 * n1; i++) {
#         A[i] = (double) rand() / RAND_MAX;
#     }
#     for (int i = 0; i < m2 * n2; i++) {
#         B[i] = (double) rand() / RAND_MAX;
#     }
# 
#     
#     double total_time = 0.0;
#     for (int k = 0; k < N; k++) {
#         auto start_time = chrono::high_resolution_clock::now();
#         for (int i = 0; i < m1; i++) {
#             for (int j = 0; j < n2; j++) {
#                 double sum = 0.0;
#                 for (int h = 0; h < n1; h++) {
#                     sum += A[i*n1+h] * B[h*n2+j];
#                 }
#                 C[i*n2+j] = sum;
#             }
#         }
#         auto end_time = chrono::high_resolution_clock::now();
#         double time = chrono::duration_cast<chrono::microseconds>(end_time - start_time).count() / 1000000.0;
#         total_time += time;
#          }
# 
#     // Calculate average execution time and print result
#     double avg_time = total_time / N;
#     cout << "Average execution time: " << avg_time << " seconds" << endl;
# 
#     // Free memory
#     free(A);
#     free(B);
#     free(C);
# 
#     return 0;
# }

"""**My own example 24 - Adding C++ average execution time to the data frame**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# !g++ multma.c -o matrix_mul
# !./matrix_mul

"""**My own example 25 - Creating a Java program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile multma.java
# 
# import java.util.Random;
# 
# class Main {
# 
#   public static void main(String[] args) {
#     
#     Random r = new Random();
#     int f1,c1,f2,c2;
#     f1 = 600;
#     c1 = 100;
#     f2 = 100; 
#     c2 = 100; 
# 
#     for(int p = 0; p < 3; p ++ ){
# 
#         int[][] a =new int[f1][c1];
#         int[][] b = new int[f2][c2];
#         int[][] mul = new int [f1][c2];
# 
#         //matrix_a generation
# 
#         for(int i=0;i<f1;i++)
#         {
#         for(int j=0;j<c1;j++)
#         {
#             a[i][j]=r.nextInt(100);
#             //System.out.print(a[i][j]+"\t");
#         }
#         //System.out.print("\n");
#         }
# 
# 
#         //matrix_b generation
# 
#         for(int x=0;x<f2;x++)
#         {
#         for(int y=0;y<c2;y++)
#         {
#             b[x][y]=r.nextInt(100);
#             //System.out.print(b[x][y]+"\t");
#         }
#         //System.out.print("\n");
#         }
# 
#         if(c1 != f2){
#             return;
#         }
# 
# 
#        
# 
#         long startTime = System.nanoTime();
# 
#         for(int i=0;i<f1;i++)    
#             {    
#                 for(int j=0;j<c1;j++)    
#                     {    
#                         mul[i][j]=0;    
#                         for(int x=0;x<f2;x++)    
#                         {    
#                             mul[i][j]+=a[i][x]*b[x][j];    
#                         }    
#                     }    
#             }
# 
#         long endTime = System.nanoTime();
# 
# 
#         long duration = (endTime - startTime)/1000000; 
#         System.out.println("Tiempo "+ p + ": " + duration + " milisegundos.");
# 
#     }
#   }
# }
# !javac multma.java
# !java multma

"""**My own example 26 - Running the Java program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile matmul.js
# 
# const { performance } = require('perf_hooks');
# 
# function getRandomInt(max) {
#   return Math.floor(Math.random() * max);
# }
# 
# function matriz_gen(f,c){
#     var matriz = new Array(f);
#     for (var i = 0; i < matriz.length; i++) {
#         matriz[i] = new Array(c);
# }   
#  
#     for (var i = 0; i < f; i++) {
#         for (var j = 0; j < c; j++) {
#          matriz[i][j] = getRandomInt(100);
#         }
#     }
# 
#     return matriz;
# }
# 
# var f1 = 600;
# var c1 = 100;
# var f2 = 100;
# var c2 = 100; 
# 
# for( var p = 0; p < 10; p ++){
#     var matriz_a = matriz_gen(f1,c1);
#     var matriz_b = matriz_gen(f2,c2);
#     var mul = matriz_gen(f1,c2);
# 
#     if( c1 !== f2){
#         return 0; 
#     }
# 
# 
#     var startTime = performance.now()
#     
#         for(var i=0; i < f1;i++)    
#                 {    
#                     for(var j=0; j < c1; j++)    
#                         {    
#                             mul[i][j]=0;    
#                             for(var x=0;x<f2;x++)    
#                             {    
#                                 mul[i][j]+=matriz_a[i][x]*matriz_b[x][j];    
#                             }    
#                         }    
#                 }
#     var endTime = performance.now();
#     console.log(`The multiplication number ${p} took  ${endTime - startTime} milliseconds`);
# 
# }

"""**My own example 27 - Adding Java average execution time to the data frame**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile matmul.js
# }
# 
# 
#     var startTime = performance.now()
#     
#         for(var i=0; i < f1;i++)    
#                 {    
#                     for(var j=0; j < c1; j++)    
#                         {    
#                             mul[i][j]=0;    
#                             for(var x=0;x<f2;x++)    
#                             {    
#                                 mul[i][j]+=matriz_a[i][x]*matriz_b[x][j];    
#                             }    
#                         }    
#                 }
#     var endTime = performance.now();
#     console.log(`The multiplication number ${p} took  ${endTime - startTime} milliseconds`);
# 
# }

"""**My own example 28 - Creating a Javascript program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# %%javascript
# !pip install jupyter-js-widgets 
# function matmul(a, b) {
#   let result = new Array(a.length);
#   for (let i = 0; i < a.length; i++) {
#     result[i] = new Array(b[0].length).fill(0);
#     for (let j = 0; j < b[0].length; j++) {
#       for (let k = 0; k < a[0].length; k++) {
#         result[i][j] += a[i][k] * b[k][j];
#       }
#     }
#   }
#   return result;
# }

"""**My own example 29 - Running the Javascript program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# %%javascript
# !pip install jupyter-js-widgets 
# function matmul(a, b) {
#   let result = new Array(a.length);
#   for (let i = 0; i < a.length; i++) {
#     result[i] = new Array(b[0].length).fill(0);
#     for (let j = 0; j < b[0].length; j++) {
#       for (let k = 0; k < a[0].length; k++) {
#         result[i][j] += a[i][k] * b[k][j];
#       }
#     }
#   }
#   return result;
# }
# let a = [[1, 2, 3], [4, 5, 6]];
# let b = [[7, 8], [9, 10], [11, 12]];
# let c = matmul(a, b);
# console.log(c);

"""**My own example 30 - Adding Javascript average execution time to the data frame**"""

# Commented out IPython magic to ensure Python compatibility.
# %%javascript
# !pip install jupyter-js-widgets 
# function matmul(a, b) {
#   let result = new Array(a.length);
#   for (let i = 0; i < a.length; i++) {
#     result[i] = new Array(b[0].length).fill(0);
#     for (let j = 0; j < b[0].length; j++) {
#       for (let k = 0; k < a[0].length; k++) {
#         result[i][j] += a[i][k] * b[k][j];
#       }
#     }
#   }
#   return result;
# }
# let a = [[1, 2, 3], [4, 5, 6]];
# let b = [[7, 8], [9, 10], [11, 12]];
# let c = matmul(a, b);
# console.log(c);

"""**My own example 31 - Finding the minimun average esecuiton time in the data frame**"""

"""Python
---average attempt time : 1229.378 ms ---
"""

"""C
    Total time taken by CPU 0 attempt: 28.71280 miliseconds
"""

"""C++
    Total time taken by CPU 0 attempt:  29.33920 miliseconds
"""

""" Java (take 3 by 3)
    El tiempo total de la multiplicación es del intento 0: 33 milisegundos.
"""

""" Javascript
    The multiplication number 0 took  51.80380 milliseconds
"""

""" Numpy
    ---attempt 0 : 0.665404752110026  ---

"""**My own example 32 - Adding the Speed factor columne to the data frame**"""

# import pandas as pd
import pandas as pd 

print("Time arrays (ms)")
lst = [[1244.4679, 28.977, 28.418, 27.000, 48.391, 0.709],
       [1220.918,  27.991, 29.017, 55.000, 76.794, 0.732 ],
       [1229.89, 27.784, 28.608,  14.000, 44.216,  0.629 ],
       [1232.88, 31.053, 32.458, 33.000 ,45.059, 0.628 ],
       [1220.301, 27.759, 28.195, 38.000 , 44.559, 0.629 ]]
    
times = pd.DataFrame(lst, columns =['Python', 'C', 'C++', 'Java', 'Javascript', 'Numpy'])
print(times)

"""**My own example 33 - Sorting the the data frame by average execution time**"""

times[['Python', 'C', 'C++', 'Java', 'Javascript', 'Numpy']].mean()

"""## Why is the Python Version so Much Slower?"""

# Dynamic typing.
def mul_elemwise(xs, ys):
    return [x * y for x, y in zip(xs, ys)]

mul_elemwise([1, 2, 3, 4], [1, 2 + 0j, 3.0, 'four'])
#[type(x) for x in _]

# Interpretation overhead.
source_code = 'a + b * c'
bytecode = compile(source_code, '', 'eval')
import dis; dis.dis(bytecode)

"""## Why is the Python Version so Slow?
- Dynamic typing means that every single operation requires dispatching on the input type.
- Having an interpreter means that every instruction is fetched and dispatched at runtime.
- Other overheads:
  - Arbitrary-size integers.
  - Reference-counted garbage collection.

> This is the paradox that we have to work with when we're doing scientific or numerically-intensive Python. What makes Python fast for development -- this high-level, interpreted, and dynamically-typed aspect of the language -- is exactly what makes it slow for code execution.

- Jake VanderPlas, [*Losing Your Loops: Fast Numerical Computing with NumPy*](https://www.youtube.com/watch?v=EEUXKG97YRw)

# What Do We Do?

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/runaway.gif" alt="Drawing" style="width: 50%;"/></center>

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/thisisfine.gif" alt="Drawing" style="width: 1080px;"/></center>

- Python is slow for numerical computation because it performs dynamic dispatch on every operation we perform...

- ...but often, we just want to do the same thing over and over in a loop!

- If we don't need Python's dynamicism, we don't want to pay (much) for it.

- **Idea:** Dispatch **once per operation** instead of **once per element**.
"""

import numpy as np

data = np.array([1, 2, 3, 4])
data

data + data

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Naive dot product
# (array_data * array_data).sum()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Built-in dot product.
# array_data.dot(array_data)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# fortran_dot_product(array_data, array_data)

# Numpy won't allow us to write a string into an int array.
data[0] = "foo"

# We also can't grow an array once it's created.
data.append(3)

# We **can** reshape an array though.
two_by_two = data.reshape(2, 2)
two_by_two

"""Numpy arrays are:

- Fixed-type

- Size-immutable

- Multi-dimensional

- Fast\*

\* If you use them correctly.

# What's in an Array?
"""

arr = np.array([1, 2, 3, 4, 5, 6], dtype='int16').reshape(2, 3)
print("Array:\n", arr, sep='')
print("===========")
print("DType:", arr.dtype)
print("Shape:", arr.shape)
print("Strides:", arr.strides)
print("Data:", arr.data.tobytes())

"""# Core Operations

- Vectorized **ufuncs** for elementwise operations.
- Fancy indexing and masking for selection and filtering.
- Aggregations across axes.
- Broadcasting

# UFuncs

UFuncs (universal functions) are functions that operate elementwise on one or more arrays.
"""

data = np.arange(15).reshape(3, 5)
data

# Binary operators.
data * data

# Unary functions.
np.sqrt(data)

# Comparison operations
(data % 3) == 0

# Boolean combinators.
((data % 2) == 0) & ((data % 3) == 0)

# as of python 3.5, @ is matrix-multiply
data @ data.T

"""# UFuncs Review

- UFuncs provide efficient elementwise operations applied across one or more arrays.
- Arithmetic Operators (`+`, `*`, `/`)
- Comparisons (`==`, `>`, `!=`)
- Boolean Operators (`&`, `|`, `^`)
- Trigonometric Functions (`sin`, `cos`)
- Transcendental Functions (`exp`, `log`)

# Selections

We often want to perform an operation on just a subset of our data.
"""

sines = np.sin(np.linspace(0, 3.14, 10))
cosines = np.cos(np.linspace(0, 3.14, 10))
sines

# Slicing works with the same semantics as Python lists.
sines[0]

sines[:3]  # First three elements

sines[5:]  # Elements from 5 on.

sines[::2]  # Every other element.

# More interesting: we can index with boolean arrays to filter by a predicate.
print("sines:\n", sines)
print("sines > 0.5:\n", sines > 0.5)
print("sines[sines > 0.5]:\n", sines[sines > 0.5])

# We index with lists/arrays of integers to select values at those indices.
print(sines)
sines[[0, 4, 7]]

# Index arrays are often used for sorting one or more arrays.
unsorted_data = np.array([1, 3, 2, 12, -1, 5, 2])

sort_indices = np.argsort(unsorted_data)
sort_indices

unsorted_data[sort_indices]

market_caps = np.array([12, 6, 10, 5, 6])  # Presumably in dollars?
assets = np.array(['A', 'B', 'C', 'D', 'E'])

# Sort assets by market cap by using the permutation that would sort market caps on ``assets``.
sort_by_mcap = np.argsort(market_caps)
assets[sort_by_mcap]

# Indexers are also useful for aligning data.
print("Dates:\n", repr(event_dates))
print("Values:\n", repr(event_values))
print("Calendar:\n", repr(calendar))

print("Raw Dates:", event_dates)
print("Indices:", calendar.searchsorted(event_dates))
print("Forward-Filled Dates:", calendar[calendar.searchsorted(event_dates)])

"""On multi-dimensional arrays, we can slice along each axis independently."""

data = np.arange(25).reshape(5, 5)
data

data[:2, :2]  # First two rows and first two columns.

data[:2, [0, -1]]  # First two rows, first and last columns.

data[(data[:, 0] % 2) == 0]  # Rows where the first column is divisible by two.

"""# Selections Review

- Indexing with an integer removes a dimension.
- Slicing operations work on Numpy arrays the same way they do on lists.
- Indexing with a boolean array filters to True locations.
- Indexing with an integer array selects indices along an axis.
- Multidimensional arrays can apply selections independently along different axes.

## Reductions

Functions that reduce an array to a scalar.

$Var(X) = \frac{1}{N}\sqrt{\sum_{i=1}^N (x_i - \bar{x})^2}$
"""

def variance(x):
    return ((x - x.mean()) ** 2).sum() / len(x)

variance(np.random.standard_normal(1000))

"""- `sum()` and `mean()` are both **reductions**.

- In the simplest case, we use these to reduce an entire array into a single value...
"""

data = np.arange(30)
data.mean()

"""- ...but we can do more interesting things with multi-dimensional arrays."""

data = np.arange(30).reshape(3, 10)
data

data.mean()

data.mean(axis=0)

data.mean(axis=1)

"""## Reductions Review

- Reductions allow us to perform efficient aggregations over arrays.
- We can do aggregations over a single axis to collapse a single dimension.
- Many built-in reductions (`mean`, `sum`, `min`, `max`, `median`, ...).

# Broadcasting
"""

row = np.array([1, 2, 3, 4])
column = np.array([[1], [2], [3]])
print("Row:\n", row, sep='')
print("Column:\n", column, sep='')

row + column

"""<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/broadcasting.png" alt="Drawing" style="width: 60%;"/></center>

<h5>Source: http://www.scipy-lectures.org/_images/numpy_broadcasting.png</h5>
"""

# Broadcasting is particularly useful in conjunction with reductions.
print("Data:\n", data, sep='')
print("Mean:\n", data.mean(axis=0), sep='')
print("Data - Mean:\n", data - data.mean(axis=0), sep='')

"""# Broadcasting Review

- Numpy operations can work on arrays of different dimensions as long as the arrays' shapes are still "compatible".
- Broadcasting works by "tiling" the smaller array along the missing dimension.
- The result of a broadcasted operation is always at least as large in each dimension as the largest array in that dimension.

# Numpy Review

- Numerical algorithms are slow in pure Python because the overhead dynamic dispatch dominates our runtime.

- Numpy solves this problem by:
  1. Imposing additional restrictions on the contents of arrays.
  2. Moving the inner loops of our algorithms into compiled C code.

- Using Numpy effectively often requires reworking an algorithms to use vectorized operations instead of for-loops, but the resulting operations are usually simpler, clearer, and faster than the pure Python equivalent.

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/unicorn.jpg" alt="Drawing" style="width: 75%;"/></center>

Numpy is great for many things, but...

- Sometimes our data is equipped with a natural set of **labels**:
  - Dates/Times
  - Stock Tickers
  - Field Names (e.g. Open/High/Low/Close)

- Sometimes we have **more than one type of data** that we want to keep grouped together.
  - Tables with a mix of real-valued and categorical data.

- Sometimes we have **missing** data, which we need to ignore, fill, or otherwise work around.

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/panda-wrangling.gif" alt="Drawing" style="width: 75%;"/></center>

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/pandas_logo.png" alt="Drawing" style="width: 75%;"/></center>

Pandas extends Numpy with more complex data structures:

- `Series`: 1-dimensional, homogenously-typed, labelled array.
- `DataFrame`: 2-dimensional, semi-homogenous, labelled table.

Pandas also provides many utilities for: 
- Input/Output
- Data Cleaning
- Rolling Algorithms
- Plotting

# Selection in Pandas
"""

s = pd.Series(index=['a', 'b', 'c', 'd', 'e'], data=[1, 2, 3, 4, 5])
s

# There are two pieces to a Series: the index and the values.
print("The index is:", s.index)
print("The values are:", s.values)

# We can look up values out of a Series by position...
s.iloc[0]

# ... or by label.
s.loc['a']

# Slicing works as expected...
s.iloc[:2]

# ...but it works with labels too!
s.loc[:'c']

# Fancy indexing works the same as in numpy.
s.iloc[[0, -1]]

# As does boolean masking.
s.loc[s > 2]

# Element-wise operations are aligned by index.
other_s = pd.Series({'a': 10.0, 'c': 20.0, 'd': 30.0, 'z': 40.0})
other_s

s + other_s

# We can fill in missing values with fillna().
(s + other_s).fillna(0.0)

# Most real datasets are read in from an external file format.
aapl = pd.read_csv('AAPL.csv', parse_dates=['Date'], index_col='Date')
aapl.head()

# Slicing generalizes to two dimensions as you'd expect:
aapl.iloc[:2, :2]

aapl.loc[pd.Timestamp('2010-02-01'):pd.Timestamp('2010-02-04'), ['Close', 'Volume']]

"""# Rolling Operations

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/rolling.gif" alt="Drawing" style="width: 75%;"/></center>
"""

aapl.rolling(5)[['Close', 'Adj Close']].mean().plot();

# Drop `Volume`, since it's way bigger than everything else.
aapl.drop('Volume', axis=1).resample('2W').max().plot();

# 30-day rolling exponentially-weighted stddev of returns.
aapl['Close'].pct_change().ewm(span=30).std().plot();

"""# "Real World" Data"""

from demos.avocados import read_avocadata

avocados = read_avocadata('2014', '2016')
avocados.head()

# Unlike numpy arrays, pandas DataFrames can have a different dtype for each column.
avocados.dtypes

# What's the regional average price of a HASS avocado every day?
hass = avocados[avocados.Variety == 'HASS']
hass.groupby(['Date', 'Region'])['Weighted Avg Price'].mean().unstack().ffill().plot();

def _organic_spread(group):

    if len(group.columns) != 2:
        return pd.Series(index=group.index, data=0.0)
    
    is_organic = group.columns.get_level_values('Organic').values.astype(bool)
    organics = group.loc[:, is_organic].squeeze()
    non_organics = group.loc[:, ~is_organic].squeeze()
    diff = organics - non_organics
    return diff

def organic_spread_by_region(df):
    """What's the difference between the price of an organic 
    and non-organic avocado within each region?
    """
    return (
        df
        .set_index(['Date', 'Region', 'Organic'])
         ['Weighted Avg Price']
        .unstack(level=['Region', 'Organic'])
        .ffill()
        .groupby(level='Region', axis=1)
        .apply(_organic_spread)
    )

organic_spread_by_region(hass).plot();
plt.gca().set_title("Daily Regional Organic Spread");
plt.legend(bbox_to_anchor=(1, 1));

spread_correlation = organic_spread_by_region(hass).corr()
spread_correlation

import seaborn as sns
grid = sns.clustermap(spread_correlation, annot=True)
fig = grid.fig
axes = fig.axes
ax = axes[2]
ax.set_xticklabels(ax.get_xticklabels(), rotation=45);

"""# Pandas Review

- Pandas extends numpy with more complex datastructures and algorithms.
- If you understand numpy, you understand 90% of pandas.
- `groupby`, `set_index`, and `unstack` are powerful tools for working with categorical data.
- Avocado prices are surprisingly interesting :)

# Thanks!
"""